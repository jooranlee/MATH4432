{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BonusQuestion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfD1RQqVjkRD",
        "outputId": "6dc1275e-8791-4f89-804c-47defb106e69"
      },
      "source": [
        "install.packages(\"HistData\")\n",
        "library(HistData)\n",
        "\n",
        "install.packages(\"FNN\")\n",
        "library(FNN)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EMAJzAloKSF"
      },
      "source": [
        "This report presents an attempt to predict childHeight by combining the prediction of different models or also known as ensemble learning. Instead of picking several new models, I simply use the baseline model, linear regression, as one of the models and one of the simplest and best-known non-parametric methods, KNN regression, as the other one. In this experiment, I would like to see how far I can improve the accuracy of linear regression by taking the prediction by KNN regression into consideration before we conclude with the final predicted childHeight. Followings the the steps of the experiments:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWUFDt806ONw"
      },
      "source": [
        "1. Add a new variable gender_bin to allow knn to measure the distance of the father, mother, and also gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AH_Uz5ksgeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0adb72-dacb-4572-e552-c7dba00eb10f"
      },
      "source": [
        "data(GaltonFamilies)\n",
        "gender_bin <- rep(0, nrow(GaltonFamilies))\n",
        "gender_bin[GaltonFamilies$gender == 'male'] <- 1\n",
        "GaltonFamilies <- data.frame(GaltonFamilies, gender_bin)\n",
        "\n",
        "print(head(GaltonFamilies))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  family father mother midparentHeight children childNum gender childHeight\n",
            "1    001   78.5   67.0           75.43        4        1   male        73.2\n",
            "2    001   78.5   67.0           75.43        4        2 female        69.2\n",
            "3    001   78.5   67.0           75.43        4        3 female        69.0\n",
            "4    001   78.5   67.0           75.43        4        4 female        69.0\n",
            "5    002   75.5   66.5           73.66        4        1   male        73.5\n",
            "6    002   75.5   66.5           73.66        4        2   male        72.5\n",
            "  gender_bin\n",
            "1          1\n",
            "2          0\n",
            "3          0\n",
            "4          0\n",
            "5          1\n",
            "6          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJOij7c6lg7"
      },
      "source": [
        "2. Sample train and test set. Since there are multiple children sampled from each family, I further preprocess the traindata such that for each family there is only one child per gender. This is to prevent high leverage of a family or children from the same family ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhVvCcgv6mFc",
        "outputId": "ba02c0ab-4ba5-4cd2-bc45-7a165e550add"
      },
      "source": [
        "n <- dim(GaltonFamilies)[1]\n",
        "ntest <- 200\n",
        "train <- sample(1:n, n-ntest, replace = FALSE) \n",
        "\n",
        "temp_traindata <- GaltonFamilies[train,c(\"family\", \"father\", \"mother\", \"gender_bin\", \"childHeight\")]\n",
        "traindata<-temp_traindata[0,]\n",
        "for (f in unique(temp_traindata$family)){\n",
        "    fam = subset(temp_traindata, family==f)\n",
        "    for (g in unique(fam$gender_bin)){\n",
        "        gen = subset(fam, gender_bin==g)\n",
        "        df<-data.frame(mean(gen$father),mean(gen$mother), g, mean(gen$childHeight))\n",
        "        names(df)<-c(\"father\",\"mother\",\"gender_bin\",\"childHeight\")\n",
        "        traindata = rbind(traindata, df)\n",
        "    }\n",
        "}\n",
        "testdata <- GaltonFamilies[-train,c(\"father\", \"mother\", \"gender_bin\", \"childHeight\")]\n",
        "\n",
        "print(head(temp_traindata[order(temp_traindata$family),]))\n",
        "print(head(traindata))\n",
        "print(head(testdata))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  family father mother gender_bin childHeight\n",
            "3    001   78.5   67.0          0        69.0\n",
            "1    001   78.5   67.0          1        73.2\n",
            "6    002   75.5   66.5          1        72.5\n",
            "8    002   75.5   66.5          0        65.5\n",
            "7    002   75.5   66.5          0        65.5\n",
            "5    002   75.5   66.5          1        73.5\n",
            "  father mother gender_bin childHeight\n",
            "1     69   68.5          1    72.00000\n",
            "2     69   68.5          0    64.91667\n",
            "3     70   67.0          1    69.00000\n",
            "4     70   67.0          0    63.33333\n",
            "5     68   64.0          0    64.00000\n",
            "6     68   64.0          1    68.50000\n",
            "   father mother gender_bin childHeight\n",
            "2    78.5   67.0          0        69.2\n",
            "4    78.5   67.0          0        69.0\n",
            "11   75.0   64.0          1        70.5\n",
            "14   75.0   64.0          0        64.5\n",
            "19   75.0   58.5          0        66.5\n",
            "20   75.0   58.5          0        62.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEbTq8Td6hhf"
      },
      "source": [
        "3. Fit the baseline model and the knn regression using all the variables, namely father, mother, and gender_bin. The parameter of KNN is found by running a few experiments that achieves the best accuracy. The 3 nearest neighbors are extracted beforehand for future usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQrb5csB71-u",
        "outputId": "c2bf9ab2-44c7-4800-bb44-16c75903ecae"
      },
      "source": [
        "fit_baseline <- lm(childHeight ~ ., data = traindata)\n",
        "\n",
        "knn_k = 3\n",
        "k <- knn(\n",
        "    traindata[,c(\"father\", \"mother\", \"gender_bin\")], \n",
        "    testdata[,c(\"father\", \"mother\", \"gender_bin\")], \n",
        "    traindata[,\"childHeight\"], \n",
        "    k = knn_k)\n",
        "indices = attr(k, \"nn.index\")\n",
        "height_baseline_pred <- c(0,ntest)\n",
        "\n",
        "print(head(indices))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     [,1] [,2] [,3]\n",
            "[1,]  147  148   89\n",
            "[2,]  286  320  287\n",
            "[3,]  286  320  287\n",
            "[4,]   84   85  319\n",
            "[5,]   85   84  319\n",
            "[6,]  267  301  266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSj_xdob8ZyS"
      },
      "source": [
        "4. Predict the childHeight and measure the MSE. Although KNN would try to find the nearest neighbors and I have set the gender_bin as one of the distance, it could still found that the nearest neighbor is of a different gender. In this case, there may be no nearest neighbors of the same gender. As mentioned in lecture, male is generally 8% taller than female. Thus, the prediction by KNN may need to be adjusted to match the gender of the testdata. In this experiment, I try to apply different weightings based on the number of different gender of those of the nearest neighbors and the testdata. Finally, I use the weighted average to combine the prediction from the baseline model and KNN regression, where each weight is also found by experiment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewgqLiHH8eD9",
        "outputId": "e715960b-8d64-458d-9d1c-b46892390569"
      },
      "source": [
        "for (j in 1:ntest){\n",
        "    pred = predict(fit_baseline,testdata[j,])\n",
        "    diff_gen = abs(knn_k*testdata[j,]$gender_bin - sum(traindata[indices[j,],]$gender_bin))\n",
        "    if (diff_gen > (knn_k-1)){\n",
        "        alpha = 1\n",
        "    }\n",
        "    else if (diff_gen > (knn_k-2)){\n",
        "        alpha = 0.99\n",
        "    }\n",
        "    else if (diff_gen > (knn_k-3)){\n",
        "        alpha = 0.8\n",
        "    }\n",
        "    else{\n",
        "        alpha = 0.76\n",
        "    }\n",
        "    height_baseline_pred[j] <- alpha*pred + (1-alpha)*mean(traindata[indices[j,],]$childHeight)\n",
        "}\n",
        "\n",
        "print(mean((testdata$childHeight - height_baseline_pred)^2))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 4.681863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BnLY7ObAA1h"
      },
      "source": [
        "In the plot below, we observe that we can improve the baseline model by combining the prediction with those of KNN regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4cW7zp7nt9R"
      },
      "source": [
        "# based on 100 replications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_hZkTUxYQMxR",
        "outputId": "cb25ac63-5716-48eb-8ce6-fac0bdda2e0f"
      },
      "source": [
        "nrep <- 100\n",
        "MSE_bonus <- data.frame(matrix(0,nrep,1))\n",
        "names(MSE_bonus) <- c(\"lm~knn\")\n",
        "\n",
        "set.seed(1)\n",
        "\n",
        "for (i in 1:nrep){\n",
        "    #1\n",
        "    data(GaltonFamilies)\n",
        "    gender_bin <- rep(0, nrow(GaltonFamilies))\n",
        "    gender_bin[GaltonFamilies$gender == 'male'] <- 1\n",
        "    GaltonFamilies <- data.frame(GaltonFamilies, gender_bin)\n",
        "\n",
        "    #2\n",
        "    n <- dim(GaltonFamilies)[1]\n",
        "    ntest <- 200\n",
        "    train <- sample(1:n, n-ntest, replace = FALSE) \n",
        "\n",
        "    temp_traindata <- GaltonFamilies[train,c(\"family\", \"father\", \"mother\", \"gender_bin\", \"childHeight\")]\n",
        "    traindata<-temp_traindata[0,]\n",
        "    for (f in unique(temp_traindata$family)){\n",
        "        fam = subset(temp_traindata, family==f)\n",
        "        for (g in unique(fam$gender_bin)){\n",
        "            gen = subset(fam, gender_bin==g)\n",
        "            df<-data.frame(mean(gen$father),mean(gen$mother), g, mean(gen$childHeight))\n",
        "            names(df)<-c(\"father\",\"mother\",\"gender_bin\",\"childHeight\")\n",
        "            traindata = rbind(traindata, df)\n",
        "        }\n",
        "    }\n",
        "    testdata <- GaltonFamilies[-train,c(\"father\", \"mother\", \"gender_bin\", \"childHeight\")]\n",
        "\n",
        "    #3\n",
        "    fit_baseline <- lm(childHeight ~ ., data = traindata)\n",
        "\n",
        "    knn_k = 3\n",
        "    k <- knn(\n",
        "        traindata[,c(\"father\", \"mother\", \"gender_bin\")], \n",
        "        testdata[,c(\"father\", \"mother\", \"gender_bin\")], \n",
        "        traindata[,\"childHeight\"], \n",
        "        k = knn_k)\n",
        "    indices = attr(k, \"nn.index\")\n",
        "    height_baseline_pred <- c(0,ntest)\n",
        "\n",
        "    #4\n",
        "    for (j in 1:ntest){\n",
        "        pred = predict(fit_baseline,testdata[j,])\n",
        "        diff_gen = abs(knn_k*testdata[j,]$gender_bin - sum(traindata[indices[j,],]$gender_bin))\n",
        "        if (diff_gen > (knn_k-1)){\n",
        "            alpha = 1\n",
        "        }\n",
        "        else if (diff_gen > (knn_k-2)){\n",
        "            alpha = 0.99\n",
        "        }\n",
        "        else if (diff_gen > (knn_k-3)){\n",
        "            alpha = 0.8\n",
        "        }\n",
        "        else{\n",
        "            alpha = 0.76\n",
        "        }\n",
        "        height_baseline_pred[j] <- alpha*pred + (1-alpha)*mean(traindata[indices[j,],]$childHeight)\n",
        "    }\n",
        "\n",
        "    MSE_bonus[i,1] <- mean((testdata$childHeight - height_baseline_pred)^2)\n",
        "}\n",
        "sum(MSE_bonus)/nrep"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4.573529"
            ],
            "text/latex": "4.57352895086915",
            "text/markdown": "4.57352895086915",
            "text/html": [
              "4.57352895086915"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QnKt_3mD3Q6b",
        "outputId": "aa372c19-fe9e-4619-f967-54f6b8b2c710"
      },
      "source": [
        "data(GaltonFamilies)\n",
        "set.seed(1) # set random seed for the reproduciable purpose \n",
        "nrep <- 100\n",
        "n <- dim(GaltonFamilies)[1]\n",
        "ntest <- 200\n",
        "MSE <- data.frame(matrix(0,nrep,1))\n",
        "names(MSE) <- c(\"lm\")\n",
        "for (i in 1:nrep){\n",
        "# partion training data and testing data\n",
        "train <- sample(1:n, n-ntest, replace = FALSE) \n",
        "traindata <- GaltonFamilies[train,]\n",
        "testdata <- GaltonFamilies[-train,]\n",
        "# Fit a baseline model\n",
        "fit_baseline <- lm(childHeight~gender + midparentHeight, traindata)\n",
        "# make prediction based on the fitted model\n",
        "height_baseline_pred <- predict(fit_baseline,testdata)\n",
        "# Evaluate model performance\n",
        "MSE[i,1] <- mean((testdata$childHeight - height_baseline_pred)^2)\n",
        "# Warning: You should not use childNum as a predictor in your model\n",
        "# because children within a family are listed in decreasing order of height \n",
        "# for boys followed by girls\n",
        "}\n",
        "sum(MSE)/nrep #the mean squared errors of the baseline model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4.694932"
            ],
            "text/latex": "4.69493223918065",
            "text/markdown": "4.69493223918065",
            "text/html": [
              "4.69493223918065"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "6I3qY3xrTzKQ",
        "outputId": "4f6778c2-f035-4549-b1c8-3032b783b084"
      },
      "source": [
        "boxplot(data.frame(MSE, MSE_bonus))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAACOlBMVEUAAAABAQECAgIDAwMF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\nIUECIUECIUECIUGC/w/+JM1kKE/qxQAAAABJRU5ErkJggg==",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    }
  ]
}